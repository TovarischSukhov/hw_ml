{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построить классификатор, который \"угадывает\" персонажа по его фразе. Baseline: равновероятный выбор между всеми главными героями.\n",
    "Примерный план действий: выделить реплики главных персонажей, сгруппировать их по героям, нормализовать (свой выбор процедур объяснить (например, нужно ли включать в стоп-лист обсценную лексику?); из инструментов для английского удобно использовать nltk), векторизовать (например, CountVectorizer), отрезать поверочную выборку (эту часть не трогаем до последней проверки). На оставшейся, большей, части данных: 1) немного поанализировать данные, чтобы понять, какие признаки могут помочь при обучении — например, построить частотные списки и сравнить их (достаточно ли матрицы терм-документ с ненормализованными вхождениями слов?);  2) обучить модели (лес, наивный байес, логит) и подобрать их оптимальные параметры. Интерпретировать параметры (атрибуты) лучших моделей. Протестировать их на проверочной выборке, выбрать лучшую модель, проиллюстрировать результат (например, нарисовать decision surface). Сравнить результат с нехитрым Baseline классификатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Going away? For how long?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Forever.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Chef</td>\n",
       "      <td>I'm sorry boys.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season Episode Character                                               Line\n",
       "0     10       1      Stan         You guys, you guys! Chef is going away. \\n\n",
       "1     10       1      Kyle                        Going away? For how long?\\n\n",
       "2     10       1      Stan                                         Forever.\\n\n",
       "3     10       1      Chef                                  I'm sorry boys.\\n\n",
       "4     10       1      Stan  Chef said he's been bored, so he joining a gro..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how raw daata looks like\n",
    "raw_data = pd.read_csv('./SouthParkData/All-seasons.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3950</td>\n",
       "      <td>64301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Cartman</td>\n",
       "      <td>What?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6416</td>\n",
       "      <td>5271</td>\n",
       "      <td>9774</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season Episode Character     Line\n",
       "count   70896   70896     70896    70896\n",
       "unique     19      19      3950    64301\n",
       "top         2      10   Cartman  What?\\n\n",
       "freq     6416    5271      9774      361"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#little summary, not all lines are unique. Moreover alot of characters\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Character\n",
       "Cartman               9774\n",
       "Stan                  7680\n",
       "Kyle                  7099\n",
       "Butters               2602\n",
       "Randy                 2467\n",
       "Mr. Garrison          1002\n",
       "Chef                   917\n",
       "Kenny                  881\n",
       "Sharon                 862\n",
       "Mr. Mackey             633\n",
       "Gerald                 626\n",
       "Jimmy                  597\n",
       "Wendy                  585\n",
       "Liane                  582\n",
       "Sheila                 566\n",
       "Jimbo                  556\n",
       "Announcer              407\n",
       "Stephen                357\n",
       "Craig                  326\n",
       "Clyde                  317\n",
       "Jesus                  312\n",
       "Linda                  290\n",
       "Principal Victoria     289\n",
       "Terrance               282\n",
       "Mrs. Garrison          282\n",
       "Token                  278\n",
       "Timmy                  263\n",
       "Mayor                  245\n",
       "Tweek                  233\n",
       "Phillip                222\n",
       "                      ... \n",
       "M.C                      1\n",
       "MJ's Hologram            1\n",
       "Ma'am                    1\n",
       "Madonna                  1\n",
       "Magician                 1\n",
       "Male Activist            1\n",
       "Male Aide                1\n",
       "Male Crew 1              1\n",
       "Male Guest               1\n",
       "Male Member              1\n",
       "Male Psychic 2           1\n",
       "Male Sailor 1            1\n",
       "Male Sailor 2            1\n",
       "Male hippie              1\n",
       "Man 29                   1\n",
       "Male passenger           1\n",
       "Man 18                   1\n",
       "Man 19                   1\n",
       "Man 2 in Crowd           1\n",
       "Man 2, Woman 2           1\n",
       "Man 20                   1\n",
       "Man 21                   1\n",
       "Man 22                   1\n",
       "Man 23                   1\n",
       "Man 24                   1\n",
       "Man 25                   1\n",
       "Man 26                   1\n",
       "Man 27                   1\n",
       "Man 28                   1\n",
       "A Banana                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count lines for character. Data have big \"tale\" of more or less unique characters\n",
    "#It seems reasonable to take only those caracters, who spoke at least 100 times (sligtly more than once per episode)\n",
    "raw_data.groupby(['Character']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29622</td>\n",
       "      <td>29622</td>\n",
       "      <td>29622</td>\n",
       "      <td>29622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>27053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>Cartman</td>\n",
       "      <td>What?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2422</td>\n",
       "      <td>2245</td>\n",
       "      <td>9774</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season Episode Character     Line\n",
       "count   29622   29622     29622    29622\n",
       "unique     18      18         5    27053\n",
       "top         6       8   Cartman  What?\\n\n",
       "freq     2422    2245      9774      207"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_speakers = raw_data.groupby(['Character']).size(\n",
    "    ).loc[raw_data.groupby(['Character']).size() > 2000]\n",
    "#print(top_speakers.index.values)\n",
    "main_char_lines = raw_data.loc[raw_data['Character'].isin(top_speakers.index.values)]\n",
    "main_char_lines.describe()\n",
    "#main_char_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ksenia/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "main_char_lines['Line'] = [line.replace('\\n','') for line in main_char_lines['Line']]\n",
    "train, test = train_test_split(main_char_lines, test_size=0.3, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "st = LancasterStemmer()\n",
    "def token(text):\n",
    "    txt = nltk.word_tokenize(text.lower())\n",
    "    return [st.stem(word) for word in txt]\n",
    "\n",
    "\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "cv = CountVectorizer(#lowercase=True, \n",
    "                     tokenizer=token, #stop_words=stop,# token_pattern=u'(?u)\\b\\w\\w+\\b',\n",
    "                     analyzer=u'word', min_df=4)\n",
    "#print(train['Line'].tolist())\n",
    "\n",
    "vec_train = cv.fit_transform(train['Line'].tolist())\n",
    "vec_test = cv.transform(test['Line'].tolist())\n",
    "\n",
    "#print(vec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47858107278752915"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "nb = MultinomialNB()\n",
    "print()\n",
    "nb.fit(vec_train, train['Character'])\n",
    "\n",
    "accuracy_score(nb.predict(vec_test), test['Character'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46584899291099358"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()#multi_class='multinomial')\n",
    "lr.fit(X = vec_train, y = train['Character'])\n",
    "\n",
    "accuracy_score(lr.predict(vec_test), test['Character'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47723088253344792"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X = vec_train, y = train['Character'])\n",
    "\n",
    "accuracy_score(rf.predict(vec_test), test['Character'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.457017640262\n",
      "0.462624278876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, vec_train, train['Character'])\n",
    "print(scores.mean())\n",
    "clf.fit(vec_train, train['Character'])\n",
    "print(accuracy_score(clf.predict(vec_test), test['Character']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
